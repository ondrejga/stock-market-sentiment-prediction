{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rudtwy44dy5p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import ta\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_sentiment_data(filepath: str, ticker: str) -> pd.DataFrame:\n",
        "    \"\"\"Load sentiment dataset and process for a given ticker.\"\"\"\n",
        "    data = pd.read_csv(filepath)\n",
        "    ticker_data = data[data['Stock Name'] == ticker].copy()\n",
        "\n",
        "    # Convert and clean date\n",
        "    ticker_data['Date'] = pd.to_datetime(ticker_data['Date'])\n",
        "    ticker_data['Day'] = ticker_data['Date'].dt.date\n",
        "\n",
        "    # Drop irrelevant columns\n",
        "    ticker_data.drop(columns=['Stock Name', 'Tweet', 'Company Name', 'Date'], inplace=True)\n",
        "    ticker_data.rename(columns={'Day': 'Date'}, inplace=True)\n",
        "\n",
        "    # Aggregate sentiment scores by date\n",
        "    sentiment_daily = ticker_data.groupby('Date').mean().reset_index()\n",
        "    return sentiment_daily"
      ],
      "metadata": {
        "id": "3gcRy0Yod9HE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_stock_data(ticker: str, sentiment_dates: pd.Series) -> pd.DataFrame:\n",
        "    \"\"\"Download stock price data, add technical indicators, and align with sentiment dates.\"\"\"\n",
        "    delta = timedelta(days=50)\n",
        "    delta1 = timedelta(days=1)\n",
        "\n",
        "    start_date = min(sentiment_dates - delta)\n",
        "    end_date = max(sentiment_dates + delta1)\n",
        "\n",
        "    # Download stock data\n",
        "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
        "    stock_data.columns = stock_data.columns.droplevel(level=1)  # Remove multi-index\n",
        "    stock_data.reset_index(inplace=True)\n",
        "\n",
        "    # Simplify date\n",
        "    stock_data['Date'] = stock_data['Date'].dt.date\n",
        "\n",
        "    # Add technical indicators\n",
        "    stock_data['SMA_10'] = ta.trend.sma_indicator(stock_data['Close'], window=10)\n",
        "    stock_data['SMA_20'] = ta.trend.sma_indicator(stock_data['Close'], window=20)\n",
        "    stock_data['RSI'] = ta.momentum.rsi(stock_data['Close'], window=14)\n",
        "\n",
        "    macd = ta.trend.MACD(stock_data['Close'])\n",
        "    stock_data['MACD'] = macd.macd()\n",
        "    stock_data['MACD_signal'] = macd.macd_signal()\n",
        "\n",
        "    return stock_data"
      ],
      "metadata": {
        "id": "wnaeKjjbd-x9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_datasets(stock_data: pd.DataFrame, sentiment_data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Merge stock data and sentiment data on date.\"\"\"\n",
        "    merged = pd.merge(stock_data, sentiment_data, on='Date', how='inner')\n",
        "    merged.sort_values(by='Date', inplace=True)\n",
        "    merged.drop(columns=['Date'], inplace=True)  # Drop date after merge\n",
        "    return merged"
      ],
      "metadata": {
        "id": "hfPre-1WeBnF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(data: pd.DataFrame, train_ratio=0.7, val_ratio=0.15):\n",
        "    \"\"\"Split dataset into train, validation, and test sets.\"\"\"\n",
        "    total_samples = len(data)\n",
        "    train_size = round(total_samples * train_ratio)\n",
        "    val_size = round(total_samples * val_ratio)\n",
        "\n",
        "    df_train = data.iloc[:train_size].copy()\n",
        "    df_val = data.iloc[train_size:train_size + val_size].copy()\n",
        "    df_test = data.iloc[train_size + val_size:].copy()\n",
        "\n",
        "    return df_train, df_val, df_test"
      ],
      "metadata": {
        "id": "61duWd4YeEtG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_sequences(data: pd.DataFrame, lag: int = 5):\n",
        "    \"\"\"Convert dataframe into sequences of features and labels.\"\"\"\n",
        "    X, y = [], []\n",
        "    features = ['Close', 'High', 'Low', 'Open', 'Volume',\n",
        "                'SMA_10', 'SMA_20', 'RSI', 'MACD', 'MACD_signal',\n",
        "                'positive', 'neutral', 'negative']\n",
        "\n",
        "    for idx in range(len(data) - lag):\n",
        "        X.append(data.iloc[idx:idx + lag][features].values)\n",
        "\n",
        "        if idx + lag + 1 >= len(data):\n",
        "            y.append(0)\n",
        "            continue\n",
        "\n",
        "        label = 1 if data.iloc[idx + lag - 1]['Close'] < data.iloc[idx + lag]['Close'] else 0\n",
        "        y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "cTwrR_7CeGbt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_ticker(ticker: str, sentiment_filepath: str = \"data_sentiment.csv\"):\n",
        "    \"\"\"Run full pipeline for a single ticker and return datasets.\"\"\"\n",
        "    sentiment_data = load_and_process_sentiment_data(sentiment_filepath, ticker)\n",
        "    stock_data = load_and_process_stock_data(ticker, sentiment_data['Date'])\n",
        "    merged_data = merge_datasets(stock_data, sentiment_data)\n",
        "\n",
        "    df_train, df_val, df_test = split_dataset(merged_data)\n",
        "\n",
        "    train_X, train_y = make_sequences(df_train)\n",
        "    val_X, val_y = make_sequences(df_val)\n",
        "    test_X, test_y = make_sequences(df_test)\n",
        "\n",
        "    return train_X, train_y, val_X, val_y, test_X, test_y"
      ],
      "metadata": {
        "id": "ehhLyyaQfKzV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    tickers = ['TSLA', 'MSFT', 'PG', 'META', 'AMZN', 'GOOG', 'AMD', 'AAPL']\n",
        "\n",
        "    for ticker in tickers:\n",
        "        print(f\"Processing {ticker}...\")\n",
        "\n",
        "        train_X, train_y, val_X, val_y, test_X, test_y = process_ticker(ticker)\n",
        "\n",
        "        # Save all datasets for this ticker in one compressed .npz file\n",
        "        np.savez_compressed(\n",
        "            f\"datasets/{ticker}_data.npz\",  # all files go into a datasets/ folder\n",
        "            train_X=train_X, train_y=train_y,\n",
        "            val_X=val_X, val_y=val_y,\n",
        "            test_X=test_X, test_y=test_y\n",
        "        )"
      ],
      "metadata": {
        "id": "XYT0VT7UfMde"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh0Ia2jSfM-G",
        "outputId": "fd96daa9-cffc-4c6a-b30a-33aabfca75e3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing TSLA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-897376755.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing MSFT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-897376755.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing PG...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-897376755.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing META...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-897376755.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing AMZN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-897376755.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing GOOG...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-897376755.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing AMD...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-897376755.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing AAPL...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-897376755.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    }
  ]
}